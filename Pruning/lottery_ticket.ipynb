{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lottery ticket hypothesis test\n",
    "\n",
    "#### Here is a notebook that aims to find the 'lottery ticket', which is an hypothesis that says that there exists a sub-neural net within your whole NN that could do the same results with significantly less connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import codecarbon\n",
    "from codecarbon import EmissionsTracker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base functions and class\n",
    "\n",
    "We here create the base model class and the base functions to load the data, train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(): # Load MNIST dataset\n",
    "    transform = torchvision.transforms.Compose([ # Preprocess images\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform) # Load training set\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) # Create dataloader\n",
    "    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform) # Load test set \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) # Create dataloader\n",
    "    return trainloader, testloader\n",
    "\n",
    "class MNIST_Model(torch.nn.Module): # Define model\n",
    "    def __init__(self):\n",
    "        super(MNIST_Model, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = torch.nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): # Forward pass\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=2): # Train model\n",
    "    for epoch in range(epochs): # Loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0): # Get the inputs\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad() # Zero the parameter gradients\n",
    "            outputs = model(inputs) # Forward pass\n",
    "            loss = criterion(outputs, labels) # Compute loss\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Optimize & update weights\n",
    "            running_loss += loss.item()  # Print statistics\n",
    "            if i % 2000 == 1999: \n",
    "                print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}') \n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "\n",
    "def test_model(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # Disable gradient tracking\n",
    "        for data in testloader: # Loop over the test set\n",
    "            images, labels = data # Get the inputs\n",
    "            outputs = model(images) # Forward pass\n",
    "            _, predicted = torch.max(outputs.data, 1) # Get the class with the highest probability\n",
    "            total += labels.size(0) # Total number of labels\n",
    "            correct += (predicted == labels).sum().item() # Number of correct predictions\n",
    "    acc = 100 * correct / total # Compute accuracy\n",
    "    #print(f'Accuracy of the network on the 10000 test images: {acc:.2f}%')\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a base model to compare afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 0.919\n",
      "[1, 4000] loss: 0.211\n",
      "[1, 6000] loss: 0.136\n",
      "[1, 8000] loss: 0.119\n",
      "[1, 10000] loss: 0.097\n",
      "[1, 12000] loss: 0.091\n",
      "[1, 14000] loss: 0.071\n",
      "[2, 2000] loss: 0.064\n",
      "[2, 4000] loss: 0.064\n",
      "[2, 6000] loss: 0.066\n",
      "[2, 8000] loss: 0.061\n",
      "[2, 10000] loss: 0.064\n",
      "[2, 12000] loss: 0.048\n",
      "[2, 14000] loss: 0.055\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "trainloader, testloader = load_mnist()\n",
    "\n",
    "# Define the model\n",
    "\n",
    "model = MNIST_Model() # Create model\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() # Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Optimizer\n",
    "\n",
    "# Train the model\n",
    "\n",
    "train_model(model, trainloader, criterion, optimizer) # Train the model\n",
    "\n",
    "# Test the model\n",
    "\n",
    "model_acc = test_model(model, testloader) # Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pruning method\n",
    "\n",
    "We will create a class based on the torch.nn.utils.prune.BasePruningMethod which will permit us to create a mask on the weight in order to set them to zero\n",
    "\n",
    "We will also have a small function that counts our zero parameter to verify that it is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import prune # This module provides an interface for model pruning  \n",
    "\n",
    "class PercentagePruning(prune.BasePruningMethod): # This class aims to prune a percentage of the weights (the ones with the lowest absolute value)\n",
    "    PRUNING_TYPE = 'unstructured' # Unstructured pruning\n",
    "\n",
    "    def __init__(self, percentage): # Constructor\n",
    "        self.percentage = percentage\n",
    "\n",
    "    def compute_mask(self, tensor, default_mask): # This function computes the mask for the tensor\n",
    "        \n",
    "        mask = default_mask.clone()\n",
    "        numel = mask.numel()\n",
    "\n",
    "        if numel == 0:\n",
    "            return mask\n",
    "        \n",
    "        weight_values = tensor.flatten().abs() # Get the absolute value of the weights\n",
    "\n",
    "        k = int(numel * self.percentage) # Compute the number of weights to prune\n",
    "\n",
    "        # find threshold value\n",
    "\n",
    "        threshold = weight_values.kthvalue(k).values # Compute the threshold value for pruning the correct percentage of weights\n",
    "\n",
    "        # generate mask\n",
    "\n",
    "        return torch.abs(tensor) > threshold # Generate the mask\n",
    "        \n",
    "    \n",
    "def compute_parameters_number(model, eps = 1e-7): # This function computes the number of parameters different from zero in the model\n",
    "    weight_values = torch.cat([tensor.flatten() for name, tensor in model.state_dict().items() if 'weight' in name]) # Get the weights of the model\n",
    "    return sum(weight_values.abs() > eps).item() # Return the number of weights different from zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning our model\n",
    "\n",
    "Let's try our pruning method before iterating with it later for our hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the original model: 44190\n",
      "Number of parameters in the pruned model: 22095\n"
     ]
    }
   ],
   "source": [
    "import copy # This module provides generic shallow and deep copy operations\n",
    "pruned_model = copy.deepcopy(model) # Create a copy of the model\n",
    "\n",
    "# parameters to prune\n",
    "parameters_to_prune = [] # List of parameters to prune\n",
    "\n",
    "for name, module in pruned_model.named_modules(): # Loop over the modules of the model\n",
    "    if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear): # If the module is a convolutional or linear layer\n",
    "        parameters_to_prune.append((module, 'weight')) # Add the weights of the module to the list of parameters to prune\n",
    "\n",
    "prune.global_unstructured( # Prune the model\n",
    "    parameters_to_prune,\n",
    "    pruning_method=PercentagePruning,\n",
    "    percentage=0.5,\n",
    ")\n",
    "\n",
    "# prune remove\n",
    "for module, name in parameters_to_prune: # Loop over the parameters to prune\n",
    "    prune.remove(module, name) # Apply the mask to the weights\n",
    "\n",
    "print(f'Number of parameters in the original model: {compute_parameters_number(model)}') \n",
    "print(f'Number of parameters in the pruned model: {compute_parameters_number(pruned_model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, that it effectively set the right amount of weight, let's compare the losses and fine_tune the model too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_before_retrain_acc = test_model(pruned_model, testloader) # Test the pruned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch's problem\n",
    "\n",
    "#### Pytorch doesn't support the 'true' removal of the weights, so in order to handle this problem we will modify a little the training process.\n",
    "\n",
    "We have to way of implementing this :\n",
    "\n",
    "-First, create a mask where we note who are the already pruned weights (i.e the zeros) and then while computing the gradient we set those weights' gradients to zero so that they won't be updated. However, this could not work with certain type of optimizer / loss function where the weights would still be updated.\n",
    "\n",
    "You can check this implementation below but we will use another one which is pretty similar :\n",
    "\n",
    "-We create the same mask and instead of preventing the update, we will simply set them back to zero after the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pruned_model_mask(model, trainloader, criterion, optimizer, epochs=2, eps = 1e-7): #eps because of the floating point inaccuracy\n",
    "    # this method works only with certain optimizer / loss function as sometimes the weights will still be updated even if the gradient is zero\n",
    "    locked_masks = {n: torch.abs(w) < eps for n, w in model.named_parameters() if n.endswith('weight')}  # Get a copy of the already pruned weights\n",
    "    for epoch in range(epochs): \n",
    "        running_loss = 0.0\n",
    "        for _, data in enumerate(trainloader, 0): \n",
    "            inputs, labels = data \n",
    "            optimizer.zero_grad() # Zero the parameter gradients\n",
    "            outputs = model(inputs)# Forward pass\n",
    "            loss = criterion(outputs, labels) # Compute loss\n",
    "            loss.backward() # Backward pass\n",
    "            for n, w in model.named_parameters(): # Loop over the parameters                                                                                                                                                                           \n",
    "                if w.grad is not None and n in locked_masks: # If the parameter is in the locked masks                                                                                                                                                                                   \n",
    "                    w.grad[locked_masks[n]] = 0 # Set the gradient to zero\n",
    "            optimizer.step() # Optimize & update weights\n",
    "            running_loss += loss.item()\n",
    "        if epoch % 2 == 1:\n",
    "            print(f'[{epoch + 1}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0\n",
    "    print('Finished Training')\n",
    "\n",
    "def train_pruned_model_copy(model, trainloader, criterion, optimizer, epochs=2, eps = 1e-7): #copy zero weights and paste them back after the optimizer step\n",
    "    locked_masks = {n: torch.abs(w) < eps for n, w in model.named_parameters() if n.endswith('weight')} # Get a copy of the already pruned weights\n",
    "    for epoch in range(epochs): # Loop over the dataset multiple times\n",
    "        running_loss = 0.0 # Initialize the running loss\n",
    "        for _, data in enumerate(trainloader, 0): # Get the inputs\n",
    "            inputs, labels = data # Zero the parameter gradients\n",
    "            optimizer.zero_grad() # Forward pass\n",
    "            outputs = model(inputs) # Compute loss\n",
    "            loss = criterion(outputs, labels) # Backward pass\n",
    "            loss.backward() # Optimize & update weights\n",
    "            optimizer.step() # Weights update\n",
    "\n",
    "            for n, w in model.named_parameters(): # Loop over the parameters\n",
    "                if n in locked_masks: # If the parameter is in the locked masks \n",
    "                    w.data[locked_masks[n]] = 0 # Set the weights back to zero\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        if epoch % 2 == 1:\n",
    "            print(f'[{epoch + 1}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] loss: 0.337\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train the pruned model a few epochs\n",
    "\n",
    "train_pruned_model_copy(pruned_model, trainloader, criterion, optimizer, epochs=2) # Train the pruned model a few epochs \n",
    "\n",
    "pruned_fine_tuned_acc = test_model(pruned_model, testloader)  # Test the pruned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and check pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Params\n",
      "0             Original     98.41   44190\n",
      "1               Pruned     98.37   22095\n",
      "2  Pruned + Fine-Tuned     98.37   22095\n"
     ]
    }
   ],
   "source": [
    "first_results = pd.DataFrame({\n",
    "    'Model': ['Original', 'Pruned', 'Pruned + Fine-Tuned'],\n",
    "    'Accuracy': [model_acc, pruned_before_retrain_acc, pruned_fine_tuned_acc],\n",
    "    'Params': [compute_parameters_number(model), compute_parameters_number(pruned_model), compute_parameters_number(pruned_model)]\n",
    "})\n",
    "print(first_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can already be happy with the results as we lost nearly no accuracy with our pruning, meaning that removing the less magnitude weights doesn't affect accuracy much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lottery ticket\n",
    "\n",
    "#### To check for lottery tickets, we will simply iterate the pruning over and over while always fine-tuning the pruned model so that we identify each time who are the most important weights to keep in our architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lottery_ticket(model_to_prune, criterion, train_loader, test_loader, pruning_percentage = 0.2, loops = 5, epochs = 1): # Find the lottery ticket\n",
    "    model = copy.deepcopy(model_to_prune) # Create a copy of the model\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Optimizer\n",
    "    accuracies = [test_model(model, test_loader)] # Test the model\n",
    "    param_numbers = [compute_parameters_number(model)] # Compute the number of parameters\n",
    "    print(f'Epochs: {0}, Accuracy: {accuracies[-1]}, Parameters: {param_numbers[-1]}') # Print the results\n",
    "    for _ in range(loops): # Loop over the number of loops\n",
    "        parameters_to_prune = [] # List of parameters to prune\n",
    "        for name, module in model.named_modules(): # Loop over the modules of the model\n",
    "            if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear): # If the module is a convolutional or linear layer\n",
    "                parameters_to_prune.append((module, 'weight')) # Add the weights of the module to the list of parameters to prune\n",
    "        percentage = 1 - (1 - pruning_percentage) ** (_ + 1) # Because we canno't really remove the weights, we can only prune a larger percentage of the weights each time, by carefully never updating previous pruned weights\n",
    "        print(f'Pruning {percentage * 100:.2f}% of the weights') \n",
    "        prune.global_unstructured(\n",
    "            parameters_to_prune,\n",
    "            pruning_method=PercentagePruning,\n",
    "            percentage=percentage,\n",
    "        )\n",
    "        for module, name in parameters_to_prune: # Loop over the parameters to prune\n",
    "            prune.remove(module, name) # Apply the mask to the weights\n",
    "        \n",
    "        param_numbers.append(compute_parameters_number(model)) # Compute the number of parameters\n",
    "        train_pruned_model_copy(model, train_loader, criterion, optimizer, epochs) # Fine-tune the model\n",
    "        accuracies.append(test_model(model, test_loader)) # Test the model\n",
    "\n",
    "        #save the model\n",
    "        torch.save(model.state_dict(), f\"lottery_models/model_{_}.pt\")\n",
    "\n",
    "\n",
    "        print(f'Epochs: {_+1}, Accuracy: {accuracies[-1]:.3f}, Parameters: {param_numbers[-1]}')\n",
    "\n",
    "    return model, accuracies, param_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the lottery ticket algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0, Accuracy: 98.41, Parameters: 44190\n",
      "Pruning 50.00% of the weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Epochs: 1, Accuracy: 98.790, Parameters: 22095\n",
      "Pruning 75.00% of the weights\n",
      "Finished Training\n",
      "Epochs: 2, Accuracy: 98.920, Parameters: 11048\n",
      "Pruning 87.50% of the weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Epochs: 3, Accuracy: 98.920, Parameters: 5524\n",
      "Pruning 93.75% of the weights\n",
      "Finished Training\n",
      "Epochs: 4, Accuracy: 98.540, Parameters: 2762\n",
      "Pruning 96.88% of the weights\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5, Accuracy: 98.390, Parameters: 1381\n",
      "Pruning 98.44% of the weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Epochs: 6, Accuracy: 97.350, Parameters: 691\n",
      "Pruning 99.22% of the weights\n",
      "Finished Training\n",
      "Epochs: 7, Accuracy: 94.150, Parameters: 346\n",
      "Pruning 99.61% of the weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Epochs: 8, Accuracy: 85.060, Parameters: 173\n",
      "Pruning 99.80% of the weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Epochs: 9, Accuracy: 54.630, Parameters: 87\n",
      "Pruning 99.90% of the weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n",
      "OMP: Warning #191: Forking a process while a parallel region is active is potentially unsafe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Epochs: 10, Accuracy: 31.680, Parameters: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n"
     ]
    }
   ],
   "source": [
    "tracker = EmissionsTracker(save_to_file=False, log_level='critical') # Create the tracker\n",
    "\n",
    "tracker.start() # Start the tracker\n",
    "\n",
    "lottery_ticket, accuracies, param_numbers = find_lottery_ticket(model, torch.nn.CrossEntropyLoss(), trainloader, testloader, pruning_percentage=0.5, loops=10, epochs=1) # Find the lottery ticket\n",
    "\n",
    "pruning_emissions = tracker.stop() # Stop the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning emissions: 0.0002813856342441691\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.asarray(param_numbers) / compute_parameters_number(model), accuracies, marker='o') # Plot the results\n",
    "plt.gca().invert_xaxis() # Invert the x-axis\n",
    "plt.xlabel('Parameters %')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Parameters %')\n",
    "plt.show()\n",
    "\n",
    "print(f'Pruning emissions: {pruning_emissions}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The results are really satisfying and way above the expectations ! Now let's check if it boosts the inference time or if we can't yet handle sparse matrices multiplications within Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original inference time: 0.135s\n",
      "Pruned inference time: 0.104s\n"
     ]
    }
   ],
   "source": [
    "#compare inference time for the original model and the pruned model\n",
    "\n",
    "import time\n",
    "\n",
    "def inference_time(model, testloade, num_loops = 100, warmup = 10):\n",
    "\n",
    "    #warmup\n",
    "    for i, data in enumerate(testloader, 0): #warmup to avoid the first iterations to be slower\n",
    "        if i == warmup: # Stop the loop after warmup\n",
    "            break\n",
    "        inputs, _ = data\n",
    "        model(inputs)\n",
    "\n",
    "    start = time.time()\n",
    "    tracker = codecarbon.EmissionsTracker(log_level='critical', save_to_file=False) # Create the tracker\n",
    "    tracker.start() # Start the tracker\n",
    "    for i, data in enumerate(testloader, 0):  # Loop over the test set\n",
    "        if i == num_loops: # Stop the loop after num_loops\n",
    "            break\n",
    "        inputs, _ = data\n",
    "        model(inputs)\n",
    "    total_em = tracker.stop() # Stop the tracker\n",
    "    end = time.time() # End time\n",
    "\n",
    "    return (end - start) / num_loops, total_em / num_loops\n",
    "\n",
    "original_inference_time, original_emissions = inference_time(model, testloader)\n",
    "\n",
    "pruned_inference_time, pruned_emissions = inference_time(lottery_ticket, testloader)\n",
    "\n",
    "print(f'Original inference time: {original_inference_time:.3f}s')\n",
    "\n",
    "print(f'Pruned inference time: {pruned_inference_time:.3f}s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try with a more realistic model, the 4th one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned inference time: 0.129s\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "pruned_model_4 = MNIST_Model()\n",
    "pruned_model_4.load_state_dict(torch.load(\"lottery_models/model_4.pt\"))\n",
    "\n",
    "#check for inference time\n",
    "pruned_inference_time_4, pruned_emissions_4 = inference_time(pruned_model_4, testloader)\n",
    "\n",
    "print(f'Pruned inference time: {pruned_inference_time_4:.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As expected, the inference time doesn't change very much despite the large amount of pruned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model size: 180956 bytes\n",
      "Pruned model size: 180956 bytes\n",
      "Pruned model size 4: 180956 bytes\n"
     ]
    }
   ],
   "source": [
    "#model size\n",
    "import os\n",
    "def model_size(model):\n",
    "    torch.save(model.state_dict(), 'model.pt')\n",
    "    size = os.path.getsize('model.pt')\n",
    "    os.remove('model.pt')\n",
    "    return size\n",
    "\n",
    "print(f'Original model size: {model_size(model)} bytes')\n",
    "print(f'Pruned model size: {model_size(lottery_ticket)} bytes')\n",
    "print(f'Pruned model size 4: {model_size(pruned_model_4)} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe we could try quantizing the zero weights \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
